A time may come when you want or need to pull back the curtain on the mathematical pillars of machine learning such as linear algebra, calculus, statistics, probability, and so on.

You can use the exact same top-down approach.

Pick a goal or result that matters to you, and use that as a lens, filter, or sift on the topics to study and learn to the depth you need to get that result.

For example, let’s say you pick linear algebra.

A goal might be to grok SVD or PCA. These are methods used in machine learning for data projection, data reduction, and feature selection type tasks.

A top-down approach might be to:

1.  Implement the method in a high-level library such as scikit-learn and get a result.
2.  Implement the method in a lower-level library such as NumPy/SciPy and reproduce the result.
3.  Implement the method directly using matrices and matrix operations in NumPy or Octave.
4.  Study and explore the matrix arithmetic operations involved.
5.  Study and explore the matrix decomposition operations involved.
6.  Study methods for approximating the [eigendecomposition of a matrix](https://machinelearningmastery.com/introduction-to-eigendecomposition-eigenvalues-and-eigenvectors/).
7.  And so on…

The goal provides the context and you can let your curiosity define the depth of study.

Painted this way, studying math is no different to studying any other topic in programming, machine learning, or other technical subjects.

It’s highly productive, and it’s a lot of fun!