Scaling your features will help improve the quality and predictive power of your model. For example, suppose you would like to build a model to predict a target variable _credit_worthiness_ based on predictor variables such as _income_ and _credit score_. Because credit scores range from 0 to 850 while annual income could range from $25,000 to $500,000, without scaling your features, the model will be biased towards the _income_ feature. This means the weight factor associated with the _income_ parameter will be very small, which will cause the predictive model to be predicting _creditworthiness_ based only on the _income_ parameter.

In order to bring features to the same scale, we could decide to use either normalization or standardization of features. Most often, we assume data is normally distributed and default towards standardization, but that is not always the case. It is important that before deciding whether to use either standardization or normalization, you first take a look at how your features are statistically distributed. If the feature tends to be uniformly distributed, then we may use normalization (_MinMaxScale_r). If the feature is approximately Gaussian, then we can use standardization (_StandardScaler_). Again, note that whether you employ normalization or standardization, these are also approximative methods and are bound to contribute to the overall error of the model.