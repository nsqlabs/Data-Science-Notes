This is the most common mistake I see among new data scientists. While deep learning has shown state-of-the-art performance in some problem domains, like computer vision, there are plenty of other algorithms out there that are more appropiate in other cases. Linear regression and simple decision trees are still among the most useful algorithms in data science. There are metaheuristics, various simulation techniques and a bunch of other classes of algorithms that almost no one talk about anymore. Inexperienced data scientists will often think they’re “obsolete”. Well, that is just not true.

As for big data, it’s more of a problem than a solution. Most of the time, we try to keep the data at a manageable volume, only resorting to big data technologies when we have to. Also, more data does not automatically mean more value. I have previously discussed this in [Håkon Hapnes Strand's answer to Do data scientists necessarily work with big data?](https://www.quora.com/Do-data-scientists-necessarily-work-with-big-data/answer/H%C3%A5kon-Hapnes-Strand "www.quora.com")